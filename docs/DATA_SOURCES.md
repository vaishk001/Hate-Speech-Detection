# Data Sources - KRIXION Hate Speech Detection

## Dataset Overview

The KRIXION Hate Speech Detection system uses multiple data sources combined into a unified dataset.

## Primary Datasets

### 1. Hate Speech Dataset (Original)

**Source:** `data/raw/hate_speech.csv`  
**Origin:** Public hate speech corpus  
**Size:** ~25 samples (after filtering)  
**Languages:** English  
**Labels:**

- 0: Normal
- 1: Offensive
- 2: Hate

**Format:**

```csv
text,label
"This is a normal message",0
"You are stupid",1
"I hate all [group]",2
```

**Usage:**

- Training: 85%
- Testing: 15%

### 2. Augmented Samples

**Source:** `data/raw/augmented_samples.csv`  
**Origin:** Manually curated synthetic data  
**Size:** ~43 samples  
**Languages:** English, Hindi, Hinglish  
**Purpose:** Balance dataset and add multilingual support

**Examples:**

```csv
text,label
"Great work on the project!",0
"Tum bahut stupid ho",1
"I will kill you",2
```

**Usage:**

- Training: 85%
- Testing: 15%

## Combined Dataset

### Clean Data

**File:** `data/clean_data.csv`  
**Generated by:** `python -m src.data.load_data`  
**Total Samples:** 68  
**Preprocessing Steps:**

1. Load all raw CSV files from `data/raw/`
2. Normalize column names (text, label)
3. Remove duplicates
4. Drop null/empty rows
5. Preprocess text (lowercase, remove URLs, etc.)
6. Detect language (en, hi, hi-en)
7. Save to `data/clean_data.csv`

### Label Distribution

- **Normal (0):** 25 samples (37%)
- **Offensive (1):** 28 samples (41%)
- **Hate (2):** 15 samples (22%)

### Language Distribution

- **English (en):** 57 samples (84%)
- **Hindi (hi):** 1 sample (1%)
- **Hinglish (hi-en):** 10 samples (15%)

## Data Splits

### Training Set

- **Size:** ~58 samples (85%)
- **Stratified:** Yes (maintains label distribution)
- **Random State:** 42 (reproducible)

### Test Set

- **Size:** ~10 samples (15%)
- **Stratified:** Yes
- **Usage:** Model evaluation only (never used in training)

## Data Quality Notes

### Strengths

1. **Multilingual:** Includes English, Hindi, Hinglish
2. **Balanced:** Relatively balanced across classes
3. **Clean:** Preprocessed and deduplicated
4. **Labeled:** Human-verified labels

### Limitations

1. **Small Size:** Only 68 samples (insufficient for production)
2. **Domain:** Limited to social media/text messages
3. **Bias:** May not represent all demographics
4. **Coverage:** Missing many hate speech variations
5. **Context:** Single sentences (no conversation threads)

## Data Preprocessing

**Script:** `src/data/preprocess.py`  
**Function:** `preprocess_text(text: str) -> Tuple[str, str]`

**Steps:**

1. Lowercase conversion
2. URL removal (http://, https://)
3. Username removal (@mentions)
4. Special character normalization
5. Extra whitespace removal
6. Language detection (en/hi/hi-en)

**Example:**

```python
Input:  "Hey @user, Check this out: https://example.com YOU ARE STUPID!!!"
Output: ("hey check this out you are stupid", "en")
```

## Feedback Data

**File:** `data/feedback.csv`  
**Purpose:** Collect user corrections for model improvement  
**Format:**

```csv
text,label,source
"Example text",1,"user_correction"
"Another example",-1,"incorrect_flag"
```

**Labels:**

- -1: Flagged as incorrect (no correction)
- 0/1/2: User-provided correction

**Usage:** Future model retraining

## Database Storage

**File:** `data/app.db` (SQLite)  
**Tables:**

- `predictions`: All inference results
- `runs`: Training run metadata
- `annotations`: Human corrections

**Predictions Schema:**

```sql
CREATE TABLE predictions (
    id INTEGER PRIMARY KEY,
    text TEXT NOT NULL,
    lang TEXT NOT NULL,
    predicted_label INTEGER NOT NULL,
    score REAL NOT NULL,
    model_name TEXT NOT NULL,
    latency_ms INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## Data Privacy & Ethics

1. **Anonymization:** No personal identifiers in training data
2. **Consent:** Only public or synthetic data used
3. **Bias Mitigation:** Balanced representation attempted
4. **Retention:** Predictions stored locally (not shared)
5. **GDPR:** No EU personal data collected

## Future Enhancements

1. **Expand Dataset:** Target 10,000+ samples
2. **More Languages:** Add Tamil, Bengali, Urdu
3. **Context:** Include conversation threads
4. **Annotation:** Crowd-sourced labeling
5. **Active Learning:** Use feedback data for retraining

## Data Access

All data files are located in:

```
data/
├── raw/
│   ├── hate_speech.csv
│   └── augmented_samples.csv
├── clean_data.csv
├── feedback.csv
└── app.db
```

## License

- **Original Dataset:** Public domain or research use
- **Augmented Data:** Custom (project-specific)
- **Combined Dataset:** Research/educational use only

## References

1. Public hate speech corpora
2. Multilingual offensive language datasets
3. Social media toxicity datasets

## Contact

For data-related questions: [Your Email]
